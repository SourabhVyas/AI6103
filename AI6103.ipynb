{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2115bb",
   "metadata": {},
   "source": [
    "### Section 1: Introduction\n",
    "\n",
    "In this homework assignment, we will investigate the effects of hyperparameters such as initial learning rate, learning rate schedule, weight decay, and data augmentation on deep neural networks. One of the most important issues in deep learning is optimization versus regularization. \n",
    "\n",
    "Optimization is controlled by the initial learning rate and the learning rate schedule. Regularization is controlled by, among other things, weight decay and data augmentation. As a result, the values of these hyperparameters are critical for the performance of deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47745a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T13:52:18.732019Z",
     "iopub.status.busy": "2025-10-03T13:52:18.731469Z",
     "iopub.status.idle": "2025-10-03T13:52:27.471291Z",
     "shell.execute_reply": "2025-10-03T13:52:27.470670Z"
    },
    "papermill": {
     "duration": 8.74767,
     "end_time": "2025-10-03T13:52:27.472696",
     "exception": false,
     "start_time": "2025-10-03T13:52:18.725026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import os, json, time\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a6043",
   "metadata": {
    "papermill": {
     "duration": 0.004159,
     "end_time": "2025-10-03T13:52:27.481800",
     "exception": false,
     "start_time": "2025-10-03T13:52:27.477641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "CIFAR-10 with Augmentation.\n",
    "- random crop, flip, normalization\n",
    "- Batch size: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e4d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T13:52:27.491319Z",
     "iopub.status.busy": "2025-10-03T13:52:27.491016Z",
     "iopub.status.idle": "2025-10-03T13:52:46.764843Z",
     "shell.execute_reply": "2025-10-03T13:52:46.764236Z"
    },
    "papermill": {
     "duration": 19.280062,
     "end_time": "2025-10-03T13:52:46.766181",
     "exception": false,
     "start_time": "2025-10-03T13:52:27.486119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:14<00:00, 11.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465), (0.247,0.243,0.261))\n",
    "])\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465), (0.247,0.243,0.261))\n",
    "])\n",
    "\n",
    "# Load full train for splitting, and test\n",
    "full_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "val_view   = datasets.CIFAR10(root='./data', train=True, download=False, transform=transform_eval)\n",
    "test_set   = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_eval)\n",
    "\n",
    "# Create a hold-out validation split (e.g., 40k train / 10k val)\n",
    "num_train = len(full_train)  # 50,000\n",
    "val_size = 10000\n",
    "indices = np.arange(num_train)\n",
    "np.random.shuffle(indices)\n",
    "val_indices = indices[:val_size] # 10,000\n",
    "train_indices = indices[val_size:] # 40,000\n",
    "\n",
    "train_set = Subset(full_train, train_indices)\n",
    "val_set   = Subset(val_view,   val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_set,   batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_set,  batch_size=128, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b36fbd",
   "metadata": {
    "papermill": {
     "duration": 0.00658,
     "end_time": "2025-10-03T13:52:46.780184",
     "exception": false,
     "start_time": "2025-10-03T13:52:46.773604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "169edf6c",
   "metadata": {
    "papermill": {
     "duration": 0.006474,
     "end_time": "2025-10-03T13:52:46.794132",
     "exception": false,
     "start_time": "2025-10-03T13:52:46.787658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section 2: Resnet\n",
    "Please describe the unique architectural characteristics of ResNet-18, possibly by comparing to neural networks before this work (e.g., VGG-18)\n",
    "<div style=\"font-size:85%\">\n",
    "\n",
    "| Aspect | ResNet-18 | VGG-18 |\n",
    "|--------|-----------|--------|\n",
    "| Philosophy | Enable depth via residual learning so optimization remains tractable. | Improve representation by stacking many small $3 \\times 3$ convolutions sequentially. |\n",
    "| Core mapping | $H(x) = F(x) + x$ with identity skip (or projection) shortcut. | $H(x)$ learned directly with no shortcut path. |\n",
    "| Residual function | $F(x) = W_2\\,\\sigma(\\mathrm{BN}(W_1 x))$ (BasicBlock: Conv $3\\times3$–BN–ReLU–Conv $3\\times3$–BN). | Typical two-layer block: $H(x) = W_2\\,\\sigma(W_1 x)$ (Conv $3\\times3$–ReLU–Conv $3\\times3$–ReLU). |\n",
    "| Gradient flow | $\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial H(x)}\\left(1 + \\frac{\\partial F}{\\partial x}\\right)$ preserves signal via the identity path. | $\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial H(x)} \\cdot \\frac{\\partial H}{\\partial x}$ must traverse all layers; more prone to vanishing. |\n",
    "| Depth handling | Scales to $50/101/152+$ layers due to stable optimization from skips. | Deeper variants degrade without special tricks; training gets harder with depth. |\n",
    "| Normalization | BatchNorm after each convolution; ReLU after first conv in block. | Original VGG used ReLU without BatchNorm (often added in modern reproductions). |\n",
    "| Downsampling | Stride-2 conv at stage starts; identity or $1\\times1$ projection for skip when shape changes. | Max pooling between stacks; downsampling via pooling only. |\n",
    "| Classifier head | Global average pooling $\\rightarrow$ single fully connected layer $\\rightarrow$ softmax. | Large fully connected layers (e.g., $4096 \\rightarrow 4096$) $\\rightarrow$ softmax. |\n",
    "| Parameters | Fewer for similar accuracy due to GAP and residual efficiency. | More due to large FC layers and no parameter-sharing shortcuts. |\n",
    "| Regularization effects | Skip paths act like implicit ensemble/shortcut regularization; BN stabilizes. | Relies more on explicit regularization and careful initialization. |\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f625d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T13:52:46.810045Z",
     "iopub.status.busy": "2025-10-03T13:52:46.809822Z",
     "iopub.status.idle": "2025-10-03T13:52:46.824778Z",
     "shell.execute_reply": "2025-10-03T13:52:46.824193Z"
    },
    "papermill": {
     "duration": 0.023772,
     "end_time": "2025-10-03T13:52:46.825819",
     "exception": false,
     "start_time": "2025-10-03T13:52:46.802047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining resnet models\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # This is the \"stem\"\n",
    "        # For CIFAR (32x32 images), it does not perform downsampling\n",
    "        # It should downsample for ImageNet\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # four stages with three downsampling\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test_resnet18():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6fac67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T13:52:46.840506Z",
     "iopub.status.busy": "2025-10-03T13:52:46.840116Z",
     "iopub.status.idle": "2025-10-03T13:52:47.076837Z",
     "shell.execute_reply": "2025-10-03T13:52:47.076204Z"
    },
    "papermill": {
     "duration": 0.245283,
     "end_time": "2025-10-03T13:52:47.078147",
     "exception": false,
     "start_time": "2025-10-03T13:52:46.832864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ResNet18().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d19cf",
   "metadata": {
    "papermill": {
     "duration": 0.006544,
     "end_time": "2025-10-03T13:52:47.091845",
     "exception": false,
     "start_time": "2025-10-03T13:52:47.085301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Functions to train one epoch, evaluate, and plot curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33d1925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T13:52:47.106121Z",
     "iopub.status.busy": "2025-10-03T13:52:47.105882Z",
     "iopub.status.idle": "2025-10-03T13:52:47.111900Z",
     "shell.execute_reply": "2025-10-03T13:52:47.111397Z"
    },
    "papermill": {
     "duration": 0.014453,
     "end_time": "2025-10-03T13:52:47.112943",
     "exception": false,
     "start_time": "2025-10-03T13:52:47.098490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        _, pred = out.max(1)\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        _, pred = out.max(1)\n",
    "        correct += pred.eq(y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01db034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T13:52:47.127299Z",
     "iopub.status.busy": "2025-10-03T13:52:47.127069Z",
     "iopub.status.idle": "2025-10-03T13:52:47.136504Z",
     "shell.execute_reply": "2025-10-03T13:52:47.135932Z"
    },
    "papermill": {
     "duration": 0.017912,
     "end_time": "2025-10-03T13:52:47.137463",
     "exception": false,
     "start_time": "2025-10-03T13:52:47.119551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExperimentLogger:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.best_state = None\n",
    "        self.best_label = None\n",
    "        self.best_val_acc = -1.0\n",
    "    def add(self, label, history, final_train, final_val, state_dict=None, metadata=None):\n",
    "        meta = dict(metadata or {})\n",
    "        meta.setdefault('added_at', time.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        safe_history = {}\n",
    "        for k, v in history.items():\n",
    "            arr = np.asarray(v)\n",
    "            safe_history[k] = arr.tolist()\n",
    "        entry = {\n",
    "            'label': label,\n",
    "            'history': safe_history,\n",
    "            'final_train': (float(final_train[0]), float(final_train[1])),\n",
    "            'final_val':   (float(final_val[0]),   float(final_val[1])),\n",
    "            'metadata': meta\n",
    "        }\n",
    "        self.results.append(entry)\n",
    "        if final_val[1] > self.best_val_acc and state_dict is not None:\n",
    "            self.best_val_acc = float(final_val[1])\n",
    "            self.best_state = {k: v.cpu().clone() for k, v in state_dict.items()}\n",
    "            self.best_label = label\n",
    "    def summary(self):\n",
    "        for r in self.results:\n",
    "            tt = r['final_train']; vv = r['final_val']\n",
    "            print(f\"{r['label']}: Train(L={tt[0]:.4f}, A={tt[1]:.4f}) | Val(L={vv[0]:.4f}, A={vv[1]:.4f})\")\n",
    "    def save_all(self, history_dir=\"history\", models_dir=\"models\", overwrite=False):\n",
    "        os.makedirs(history_dir, exist_ok=True)\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "        for r in self.results:\n",
    "            label = r['label']\n",
    "            fname = os.path.join(history_dir, f\"{label}.json\")\n",
    "            if os.path.exists(fname) and not overwrite:\n",
    "                fname = os.path.join(history_dir, f\"{label}_{int(time.time())}.json\")\n",
    "            with open(fname, \"w\") as f:\n",
    "                json.dump(r, f, indent=4)\n",
    "        if self.best_state is not None and self.best_label is not None:\n",
    "            torch.save(self.best_state, os.path.join(models_dir, f\"{self.best_label}_best.pt\"))\n",
    "    def load_results(self, history_dir=\"history\"):\n",
    "        self.results = []\n",
    "        for fname in sorted(os.listdir(history_dir)):\n",
    "            if fname.endswith(\".json\"):\n",
    "                with open(os.path.join(history_dir, fname), \"r\") as f:\n",
    "                    self.results.append(json.load(f))\n",
    "    def select(self, label_prefix=None):\n",
    "        out = self.results\n",
    "        if label_prefix is not None:\n",
    "            out = [r for r in out if str(r['label']).startswith(label_prefix)]\n",
    "        return out\n",
    "    \n",
    "    \n",
    "logger = ExperimentLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a89f4b",
   "metadata": {
    "papermill": {
     "duration": 0.006568,
     "end_time": "2025-10-03T13:52:47.150735",
     "exception": false,
     "start_time": "2025-10-03T13:52:47.144167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section 3: Initial Learning Rate Study (15 Epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df72608",
   "metadata": {
    "papermill": {
     "duration": 0.00646,
     "end_time": "2025-10-03T13:52:47.163934",
     "exception": false,
     "start_time": "2025-10-03T13:52:47.157474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Three experiments with lr ∈ {0.1, 0.01, 0.001}, no weight decay or schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91539494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T13:52:47.177918Z",
     "iopub.status.busy": "2025-10-03T13:52:47.177719Z",
     "iopub.status.idle": "2025-10-03T14:10:34.321538Z",
     "shell.execute_reply": "2025-10-03T14:10:34.320705Z"
    },
    "papermill": {
     "duration": 1067.152668,
     "end_time": "2025-10-03T14:10:34.323171",
     "exception": false,
     "start_time": "2025-10-03T13:52:47.170503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<--- LR Sweep --->\n",
      "=== Best accuracy on validation set so far ===\n",
      "LR=0.1 | val acc=0.3898 | epoch=1\n",
      "LR=0.1 | val acc=0.4905 | epoch=2\n",
      "LR=0.1 | val acc=0.5356 | epoch=3\n",
      "LR=0.1 | val acc=0.6257 | epoch=4\n",
      "LR=0.1 | val acc=0.691 | epoch=5\n",
      "LR=0.1 | val acc=0.7009 | epoch=6\n",
      "LR=0.1 | val acc=0.745 | epoch=7\n",
      "LR=0.1 | val acc=0.7708 | epoch=8\n",
      "LR=0.1 | val acc=0.7798 | epoch=9\n",
      "LR=0.1 | val acc=0.8077 | epoch=10\n",
      "LR=0.1 | val acc=0.8156 | epoch=12\n",
      "LR=0.1 | val acc=0.8348 | epoch=13\n",
      "LR=0.1 | val acc=0.8431 | epoch=15\n",
      "LR=0.01 | val acc=0.8506 | epoch=9\n",
      "LR=0.01 | val acc=0.856 | epoch=11\n",
      "LR=0.01 | val acc=0.8671 | epoch=13\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.1, 0.01, 0.001]\n",
    "best_lr, best_acc, best_epoch = 0,0,0\n",
    "print(f\"<--- LR Sweep --->\\n=== Best accuracy on validation set so far ===\")\n",
    "for lr in lrs:\n",
    "    model = ResNet18().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.0)\n",
    "    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[], 'lr':[]}\n",
    "    for epoch in range(1, 16):\n",
    "        tl, ta = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        vl, va = evaluate(model, val_loader, criterion)\n",
    "        history['train_loss'].append(tl)\n",
    "        history['train_acc'].append(ta)\n",
    "        history['val_loss'].append(vl)\n",
    "        history['val_acc'].append(va)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        if best_acc < va:\n",
    "            best_acc = va\n",
    "            best_lr = lr\n",
    "            best_epoch = epoch\n",
    "            print(f\"LR={lr} | val acc={va} | epoch={epoch}\")\n",
    "            \n",
    "    \n",
    "    cpu_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "    logger.add(label=f\"sec3_lr={lr}\", history=history, final_train=(tl, ta), final_val=(vl, va), state_dict=cpu_state, metadata={'base_lr': lr, 'section': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320b198",
   "metadata": {
    "papermill": {
     "duration": 0.007315,
     "end_time": "2025-10-03T14:10:34.338865",
     "exception": false,
     "start_time": "2025-10-03T14:10:34.331550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<i>LR **0.01** gave the higest accuracy of **86.71%** on the validation set</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6d03f",
   "metadata": {
    "papermill": {
     "duration": 0.007115,
     "end_time": "2025-10-03T14:10:34.367919",
     "exception": false,
     "start_time": "2025-10-03T14:10:34.360804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section 4: Learning Rate Schedule (300 Epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a20ce",
   "metadata": {
    "papermill": {
     "duration": 0.007459,
     "end_time": "2025-10-03T14:10:34.382553",
     "exception": false,
     "start_time": "2025-10-03T14:10:34.375094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use best initial lr from Section 3. Compare:\n",
    "* Constant lr for 300 epochs\n",
    "* Cosine annealing such that lr → 0 over 300 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6481110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T14:10:34.398296Z",
     "iopub.status.busy": "2025-10-03T14:10:34.398015Z",
     "iopub.status.idle": "2025-10-03T18:07:46.031460Z",
     "shell.execute_reply": "2025-10-03T18:07:46.030576Z"
    },
    "papermill": {
     "duration": 14231.643589,
     "end_time": "2025-10-03T18:07:46.033361",
     "exception": false,
     "start_time": "2025-10-03T14:10:34.389772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<--- Annealing Check --->\n",
      "=== Best accuracy on validation set so far ===\n",
      "AnnealingLR=False| val acc=0.5346 | epoch=1\n",
      "AnnealingLR=False| val acc=0.6327 | epoch=2\n",
      "AnnealingLR=False| val acc=0.7045 | epoch=3\n",
      "AnnealingLR=False| val acc=0.7799 | epoch=4\n",
      "AnnealingLR=False| val acc=0.8053 | epoch=6\n",
      "AnnealingLR=False| val acc=0.8266 | epoch=8\n",
      "AnnealingLR=False| val acc=0.845 | epoch=9\n",
      "AnnealingLR=False| val acc=0.8694 | epoch=13\n",
      "AnnealingLR=False| val acc=0.8853 | epoch=17\n",
      "AnnealingLR=False| val acc=0.8882 | epoch=20\n",
      "AnnealingLR=False| val acc=0.8888 | epoch=29\n",
      "AnnealingLR=False| val acc=0.8971 | epoch=30\n",
      "AnnealingLR=False| val acc=0.8992 | epoch=31\n",
      "AnnealingLR=False| val acc=0.9083 | epoch=41\n",
      "AnnealingLR=False| val acc=0.9095 | epoch=45\n",
      "AnnealingLR=False| val acc=0.9101 | epoch=50\n",
      "AnnealingLR=False| val acc=0.9117 | epoch=51\n",
      "AnnealingLR=False| val acc=0.9123 | epoch=56\n",
      "AnnealingLR=False| val acc=0.916 | epoch=62\n",
      "AnnealingLR=False| val acc=0.9189 | epoch=81\n",
      "AnnealingLR=False| val acc=0.9221 | epoch=82\n",
      "AnnealingLR=False| val acc=0.9234 | epoch=137\n",
      "AnnealingLR=False| val acc=0.9242 | epoch=194\n",
      "AnnealingLR=False| val acc=0.9254 | epoch=195\n",
      "AnnealingLR=False| val acc=0.9263 | epoch=225\n",
      "AnnealingLR=False| val acc=0.9265 | epoch=242\n",
      "AnnealingLR=False| val acc=0.9277 | epoch=257\n",
      "AnnealingLR=False| val acc=0.9278 | epoch=264\n",
      "AnnealingLR=False| val acc=0.9285 | epoch=273\n",
      "AnnealingLR=False| val acc=0.9287 | epoch=274\n",
      "AnnealingLR=False| val acc=0.9295 | epoch=278\n",
      "AnnealingLR=False| val acc=0.9297 | epoch=283\n",
      "AnnealingLR=True| val acc=0.9307 | epoch=182\n",
      "AnnealingLR=True| val acc=0.9308 | epoch=225\n"
     ]
    }
   ],
   "source": [
    "use_cosine, best_acc = False, 0\n",
    "num_epochs = 300\n",
    "print(f\"<--- Annealing Check --->\\n=== Best accuracy on validation set so far ===\")\n",
    "for use_schedule in [False, True]:\n",
    "    model = ResNet18().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=best_lr, momentum=0.9, weight_decay=0.0)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs) if use_schedule else None\n",
    "    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[], 'lr':[]}\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        tl, ta = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        vl, va = evaluate(model, val_loader, criterion)\n",
    "        history['train_loss'].append(tl)\n",
    "        history['train_acc'].append(ta)\n",
    "        history['val_loss'].append(vl)\n",
    "        history['val_acc'].append(va)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        if best_acc < va:\n",
    "            best_acc = va\n",
    "            use_cosine = use_schedule\n",
    "            print(f\"AnnealingLR={use_schedule}| val acc={va} | epoch={epoch}\")\n",
    "            \n",
    "    label = f\"sec4_{'cosine' if use_schedule else 'constant'}_lr={best_lr}\"\n",
    "    cpu_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "    logger.add(label=label, history=history, final_train=(tl, ta), final_val=(vl, va), state_dict=cpu_state, metadata={'schedule': bool(use_schedule), 'section': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a33981",
   "metadata": {
    "papermill": {
     "duration": 0.009786,
     "end_time": "2025-10-03T18:07:46.053336",
     "exception": false,
     "start_time": "2025-10-03T18:07:46.043550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<i>Using annealing improves the accuracy to **93.08%**</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d6381",
   "metadata": {
    "papermill": {
     "duration": 0.009257,
     "end_time": "2025-10-03T18:07:46.090420",
     "exception": false,
     "start_time": "2025-10-03T18:07:46.081163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section 5: Weight Decay Study (300 Epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db772ebe",
   "metadata": {
    "papermill": {
     "duration": 0.009611,
     "end_time": "2025-10-03T18:07:46.109252",
     "exception": false,
     "start_time": "2025-10-03T18:07:46.099641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Keep best lr & cosine schedule. Compare weight decay λ ∈ {5e-4, 1e-2}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a8514e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T18:07:46.129527Z",
     "iopub.status.busy": "2025-10-03T18:07:46.129181Z",
     "iopub.status.idle": "2025-10-03T22:06:54.353572Z",
     "shell.execute_reply": "2025-10-03T22:06:54.352531Z"
    },
    "papermill": {
     "duration": 14348.236866,
     "end_time": "2025-10-03T22:06:54.355200",
     "exception": false,
     "start_time": "2025-10-03T18:07:46.118334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<--- WD Sweep --->\n",
      "=== Best accuracy on validation set so far ===\n",
      "Best Weight Decay=0.0005 | val acc=0.556 | epoch=1\n",
      "Best Weight Decay=0.0005 | val acc=0.6185 | epoch=2\n",
      "Best Weight Decay=0.0005 | val acc=0.7131 | epoch=3\n",
      "Best Weight Decay=0.0005 | val acc=0.783 | epoch=4\n",
      "Best Weight Decay=0.0005 | val acc=0.7986 | epoch=7\n",
      "Best Weight Decay=0.0005 | val acc=0.8268 | epoch=8\n",
      "Best Weight Decay=0.0005 | val acc=0.8499 | epoch=10\n",
      "Best Weight Decay=0.0005 | val acc=0.8577 | epoch=12\n",
      "Best Weight Decay=0.0005 | val acc=0.8627 | epoch=15\n",
      "Best Weight Decay=0.0005 | val acc=0.8702 | epoch=17\n",
      "Best Weight Decay=0.0005 | val acc=0.8806 | epoch=18\n",
      "Best Weight Decay=0.0005 | val acc=0.8809 | epoch=21\n",
      "Best Weight Decay=0.0005 | val acc=0.8872 | epoch=23\n",
      "Best Weight Decay=0.0005 | val acc=0.8931 | epoch=28\n",
      "Best Weight Decay=0.0005 | val acc=0.8937 | epoch=32\n",
      "Best Weight Decay=0.0005 | val acc=0.8986 | epoch=34\n",
      "Best Weight Decay=0.0005 | val acc=0.8991 | epoch=37\n",
      "Best Weight Decay=0.0005 | val acc=0.9029 | epoch=40\n",
      "Best Weight Decay=0.0005 | val acc=0.903 | epoch=42\n",
      "Best Weight Decay=0.0005 | val acc=0.9055 | epoch=53\n",
      "Best Weight Decay=0.0005 | val acc=0.9076 | epoch=54\n",
      "Best Weight Decay=0.0005 | val acc=0.9101 | epoch=59\n",
      "Best Weight Decay=0.0005 | val acc=0.9107 | epoch=71\n",
      "Best Weight Decay=0.0005 | val acc=0.9113 | epoch=74\n",
      "Best Weight Decay=0.0005 | val acc=0.9154 | epoch=79\n",
      "Best Weight Decay=0.0005 | val acc=0.9174 | epoch=90\n",
      "Best Weight Decay=0.0005 | val acc=0.9198 | epoch=103\n",
      "Best Weight Decay=0.0005 | val acc=0.9201 | epoch=125\n",
      "Best Weight Decay=0.0005 | val acc=0.9219 | epoch=138\n",
      "Best Weight Decay=0.0005 | val acc=0.923 | epoch=139\n",
      "Best Weight Decay=0.0005 | val acc=0.9264 | epoch=144\n",
      "Best Weight Decay=0.0005 | val acc=0.9266 | epoch=154\n",
      "Best Weight Decay=0.0005 | val acc=0.9268 | epoch=160\n",
      "Best Weight Decay=0.0005 | val acc=0.9276 | epoch=166\n",
      "Best Weight Decay=0.0005 | val acc=0.929 | epoch=177\n",
      "Best Weight Decay=0.0005 | val acc=0.9302 | epoch=180\n",
      "Best Weight Decay=0.0005 | val acc=0.9312 | epoch=182\n",
      "Best Weight Decay=0.0005 | val acc=0.9338 | epoch=183\n",
      "Best Weight Decay=0.0005 | val acc=0.9339 | epoch=190\n",
      "Best Weight Decay=0.0005 | val acc=0.934 | epoch=191\n",
      "Best Weight Decay=0.0005 | val acc=0.9357 | epoch=192\n",
      "Best Weight Decay=0.0005 | val acc=0.9361 | epoch=193\n",
      "Best Weight Decay=0.0005 | val acc=0.9362 | epoch=198\n",
      "Best Weight Decay=0.0005 | val acc=0.9368 | epoch=201\n",
      "Best Weight Decay=0.0005 | val acc=0.9369 | epoch=209\n",
      "Best Weight Decay=0.0005 | val acc=0.9373 | epoch=212\n",
      "Best Weight Decay=0.0005 | val acc=0.9374 | epoch=219\n",
      "Best Weight Decay=0.0005 | val acc=0.9387 | epoch=222\n",
      "Best Weight Decay=0.0005 | val acc=0.9392 | epoch=225\n",
      "Best Weight Decay=0.0005 | val acc=0.9397 | epoch=243\n",
      "Best Weight Decay=0.01 | val acc=0.9407 | epoch=258\n",
      "Best Weight Decay=0.01 | val acc=0.9439 | epoch=260\n",
      "Best Weight Decay=0.01 | val acc=0.9467 | epoch=264\n",
      "Best Weight Decay=0.01 | val acc=0.9474 | epoch=265\n",
      "Best Weight Decay=0.01 | val acc=0.9481 | epoch=276\n",
      "Best Weight Decay=0.01 | val acc=0.9484 | epoch=279\n",
      "Best Weight Decay=0.01 | val acc=0.9488 | epoch=282\n",
      "Best Weight Decay=0.01 | val acc=0.9503 | epoch=283\n"
     ]
    }
   ],
   "source": [
    "wds = [5e-4, 1e-2]\n",
    "best_wd, best_acc = 0, 0\n",
    "print(f\"<--- WD Sweep --->\\n=== Best accuracy on validation set so far ===\")\n",
    "for wd in wds:\n",
    "    model = ResNet18().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=best_lr, momentum=0.9, weight_decay=wd)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs) if use_cosine else None\n",
    "    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[], 'lr':[]}\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        tl, ta = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "        vl, va = evaluate(model, val_loader, criterion)\n",
    "        history['train_loss'].append(tl)\n",
    "        history['train_acc'].append(ta)\n",
    "        history['val_loss'].append(vl)\n",
    "        history['val_acc'].append(va)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        if best_acc < va:\n",
    "            best_wd = wd\n",
    "            best_acc = va\n",
    "            print(f\"Best Weight Decay={best_wd} | val acc={va} | epoch={epoch}\")\n",
    "            \n",
    "    label = f\"sec5_wd={wd:g}\"\n",
    "    cpu_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "    logger.add(label=label, history=history, final_train=(tl, ta), final_val=(vl, va), state_dict=cpu_state, metadata={'weight_decay': wd, 'section': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e390f0",
   "metadata": {
    "papermill": {
     "duration": 0.011209,
     "end_time": "2025-10-03T22:06:54.378489",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.367280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<i>For weight decay rate = **0.01**, accuracy improved to **95.03%**</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e44bd",
   "metadata": {
    "papermill": {
     "duration": 0.010707,
     "end_time": "2025-10-03T22:06:54.422274",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.411567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section 6: Custom Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eddf38f",
   "metadata": {
    "papermill": {
     "duration": 0.010671,
     "end_time": "2025-10-03T22:06:54.444301",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.433630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Implement BN where mean/var are detached in backprop, then replace all nn.BatchNorm2d layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac473c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T22:06:54.467710Z",
     "iopub.status.busy": "2025-10-03T22:06:54.467410Z",
     "iopub.status.idle": "2025-10-03T22:06:54.475057Z",
     "shell.execute_reply": "2025-10-03T22:06:54.474543Z"
    },
    "papermill": {
     "duration": 0.021151,
     "end_time": "2025-10-03T22:06:54.476198",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.455047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyBatchNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta  = nn.Parameter(torch.zeros(num_features))\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var',  torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # compute batch stats\n",
    "            mean = x.mean(dim=(0,2,3), keepdim=True)\n",
    "            var  = x.var(dim=(0,2,3), keepdim=True, unbiased=False)\n",
    "\n",
    "            # update running stats without tracking grads (imp: reduces gpu usage)\n",
    "            with torch.no_grad():\n",
    "                self.running_mean.mul_(1 - self.momentum) \\\n",
    "                                 .add_(self.momentum * mean.view(-1))\n",
    "                self.running_var .mul_(1 - self.momentum) \\\n",
    "                                 .add_(self.momentum * var.view(-1))\n",
    "\n",
    "            # detach mean/var\n",
    "            m, v = mean.detach(), var.detach()\n",
    "        else:\n",
    "            # inference: use running stats\n",
    "            m = self.running_mean.view(1, -1, 1, 1)\n",
    "            v = self.running_var .view(1, -1, 1, 1)\n",
    "\n",
    "        # normalize and apply scale+shift\n",
    "        x_norm = (x - m) / torch.sqrt(v + self.eps)\n",
    "        return self.gamma.view(1, -1, 1, 1) * x_norm \\\n",
    "             + self.beta .view(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c1340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T22:06:54.499148Z",
     "iopub.status.busy": "2025-10-03T22:06:54.498677Z",
     "iopub.status.idle": "2025-10-03T22:06:54.596601Z",
     "shell.execute_reply": "2025-10-03T22:06:54.595674Z"
    },
    "papermill": {
     "duration": 0.110616,
     "end_time": "2025-10-03T22:06:54.597858",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.487242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n",
      "torch.Size([4, 16, 8, 8]) torch.Size([16]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# toy input to check the layers\n",
    "x = torch.randn(4, 16, 8, 8, device=device, requires_grad=True)\n",
    "bn = MyBatchNorm2d(16).to(device)\n",
    "out = bn(x).sum()\n",
    "out.backward()\n",
    "\n",
    "print(bn.running_mean.grad, bn.running_var.grad) \n",
    "print(x.grad.shape, bn.gamma.grad.shape, bn.beta.grad.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69bd6c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T22:06:54.622140Z",
     "iopub.status.busy": "2025-10-03T22:06:54.621911Z",
     "iopub.status.idle": "2025-10-03T22:06:54.729744Z",
     "shell.execute_reply": "2025-10-03T22:06:54.728888Z"
    },
    "papermill": {
     "duration": 0.12153,
     "end_time": "2025-10-03T22:06:54.731171",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.609641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Monkey-patch and build model\n",
    "OriginalBatchNorm2d = nn.BatchNorm2d\n",
    "nn.BatchNorm2d = MyBatchNorm2d\n",
    "model_bn = ResNet18().to(device)\n",
    "nn.BatchNorm2d = OriginalBatchNorm2d # restore for safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209658fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T22:06:54.755394Z",
     "iopub.status.busy": "2025-10-03T22:06:54.754865Z",
     "iopub.status.idle": "2025-10-03T22:06:54.759523Z",
     "shell.execute_reply": "2025-10-03T22:06:54.758837Z"
    },
    "papermill": {
     "duration": 0.017976,
     "end_time": "2025-10-03T22:06:54.760593",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.742617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1                            -> MyBatchNorm2d\n",
      "layer1.0.bn1                   -> MyBatchNorm2d\n",
      "layer1.0.bn2                   -> MyBatchNorm2d\n",
      "layer1.1.bn1                   -> MyBatchNorm2d\n",
      "layer1.1.bn2                   -> MyBatchNorm2d\n",
      "layer2.0.bn1                   -> MyBatchNorm2d\n",
      "layer2.0.bn2                   -> MyBatchNorm2d\n",
      "layer2.0.shortcut.1            -> MyBatchNorm2d\n",
      "layer2.1.bn1                   -> MyBatchNorm2d\n",
      "layer2.1.bn2                   -> MyBatchNorm2d\n",
      "layer3.0.bn1                   -> MyBatchNorm2d\n",
      "layer3.0.bn2                   -> MyBatchNorm2d\n",
      "layer3.0.shortcut.1            -> MyBatchNorm2d\n",
      "layer3.1.bn1                   -> MyBatchNorm2d\n",
      "layer3.1.bn2                   -> MyBatchNorm2d\n",
      "layer4.0.bn1                   -> MyBatchNorm2d\n",
      "layer4.0.bn2                   -> MyBatchNorm2d\n",
      "layer4.0.shortcut.1            -> MyBatchNorm2d\n",
      "layer4.1.bn1                   -> MyBatchNorm2d\n",
      "layer4.1.bn2                   -> MyBatchNorm2d\n"
     ]
    }
   ],
   "source": [
    "# Verify Model\n",
    "for name, module in model_bn.named_modules():\n",
    "    if isinstance(module, (MyBatchNorm2d, OriginalBatchNorm2d)):\n",
    "        print(f\"{name:30s} -> {module.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d64453c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T22:06:54.784064Z",
     "iopub.status.busy": "2025-10-03T22:06:54.783818Z",
     "iopub.status.idle": "2025-10-03T22:06:54.789251Z",
     "shell.execute_reply": "2025-10-03T22:06:54.788649Z"
    },
    "papermill": {
     "duration": 0.018453,
     "end_time": "2025-10-03T22:06:54.790363",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.771910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 3 best: sec3_lr=0.01 | val_acc = 0.8457\n",
      "Section 4 best: sec4_cosine_lr=0.01 | val_acc = 0.9303\n",
      "Section 5 best: sec5_wd=0.01 | val_acc = 0.9499\n"
     ]
    }
   ],
   "source": [
    "best_per_section = {}\n",
    "\n",
    "for run in logger.results:\n",
    "    sec = run['metadata'].get('section', None)\n",
    "    if sec is None:\n",
    "        continue\n",
    "    \n",
    "    if (sec not in best_per_section or\n",
    "        run['final_val'][1] > best_per_section[sec]['final_val'][1]):\n",
    "        best_per_section[sec] = run\n",
    "\n",
    "# Print out the winners\n",
    "for sec, winner in sorted(best_per_section.items()):\n",
    "    acc = winner['final_val'][1]\n",
    "    print(f\"Section {sec} best: {winner['label']} | val_acc = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137f3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T22:06:54.814458Z",
     "iopub.status.busy": "2025-10-03T22:06:54.813815Z",
     "iopub.status.idle": "2025-10-03T22:06:54.818104Z",
     "shell.execute_reply": "2025-10-03T22:06:54.817371Z"
    },
    "papermill": {
     "duration": 0.017187,
     "end_time": "2025-10-03T22:06:54.819123",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.801936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR: 0.01\n",
      "Use Annealing: True\n",
      "Best Weight Decay Rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Confirm if correct variables are stored\n",
    "print(f\"Best LR: {best_lr}\")\n",
    "print(f\"Use Annealing: {use_cosine}\")\n",
    "print(f\"Best Weight Decay Rate: {best_wd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e404dbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T22:06:54.842877Z",
     "iopub.status.busy": "2025-10-03T22:06:54.842639Z",
     "iopub.status.idle": "2025-10-04T00:26:23.085449Z",
     "shell.execute_reply": "2025-10-04T00:26:23.084481Z"
    },
    "papermill": {
     "duration": 8368.25667,
     "end_time": "2025-10-04T00:26:23.087184",
     "exception": false,
     "start_time": "2025-10-03T22:06:54.830514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c45caa02534525b65bd291e3514d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/300 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train with best setting discovered (e.g., best_lr, cosine, best weight decay)\n",
    "optimizer = optim.SGD(model_bn.parameters(), lr=best_lr, momentum=0.9, weight_decay=best_wd)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs) if use_cosine else None\n",
    "\n",
    "history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[], 'lr':[]}\n",
    "for epoch in tqdm(range(1, num_epochs + 1),desc=\"Epochs\",unit=\"epoch\"):\n",
    "    tl, ta = train_one_epoch(model_bn, train_loader, optimizer, criterion)\n",
    "    vl, va = evaluate(model_bn, val_loader, criterion)\n",
    "    history['train_loss'].append(tl)\n",
    "    history['train_acc'].append(ta)\n",
    "    history['val_loss'].append(vl)\n",
    "    history['val_acc'].append(va)\n",
    "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "cpu_state = {k: v.cpu().clone() for k, v in model_bn.state_dict().items()}\n",
    "logger.add(label=\"sec6_bn\", history=history, final_train=(tl, ta), final_val=(vl, va), state_dict=cpu_state, metadata={'section': 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145338b",
   "metadata": {
    "papermill": {
     "duration": 0.011264,
     "end_time": "2025-10-04T00:26:23.110590",
     "exception": false,
     "start_time": "2025-10-04T00:26:23.099326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Final Test Accuracy\n",
    "Load the best checkpoint, evaluate on test_loader, and report accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35e19bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T00:26:23.134678Z",
     "iopub.status.busy": "2025-10-04T00:26:23.134146Z",
     "iopub.status.idle": "2025-10-04T00:26:23.138915Z",
     "shell.execute_reply": "2025-10-04T00:26:23.138276Z"
    },
    "papermill": {
     "duration": 0.018033,
     "end_time": "2025-10-04T00:26:23.139858",
     "exception": false,
     "start_time": "2025-10-04T00:26:23.121825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Summary ===\n",
      "sec3_lr=0.1: Train(L=0.3652, A=0.8728) | Val(L=0.4697, A=0.8431)\n",
      "sec3_lr=0.01: Train(L=0.2497, A=0.9126) | Val(L=0.5292, A=0.8457)\n",
      "sec3_lr=0.001: Train(L=0.3998, A=0.8605) | Val(L=0.5184, A=0.8288)\n",
      "sec4_constant_lr=0.01: Train(L=0.0003, A=1.0000) | Val(L=0.5699, A=0.9278)\n",
      "sec4_cosine_lr=0.01: Train(L=0.0002, A=1.0000) | Val(L=0.5040, A=0.9303)\n",
      "sec5_wd=0.0005: Train(L=0.0012, A=1.0000) | Val(L=0.2401, A=0.9384)\n",
      "sec5_wd=0.01: Train(L=0.0233, A=1.0000) | Val(L=0.1867, A=0.9499)\n",
      "sec6_bn: Train(L=1.9471, A=0.2491) | Val(L=1.9234, A=0.2477)\n",
      "\n",
      "Selected best by Val Acc: sec5_wd=0.01 (Val Acc=0.9499)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Experiment Summary ===\")\n",
    "logger.summary()\n",
    "print(f\"\\nSelected best by Val Acc: {logger.best_label} (Val Acc={logger.best_val_acc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e8af86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T00:26:23.163538Z",
     "iopub.status.busy": "2025-10-04T00:26:23.163289Z",
     "iopub.status.idle": "2025-10-04T00:26:25.190713Z",
     "shell.execute_reply": "2025-10-04T00:26:25.189865Z"
    },
    "papermill": {
     "duration": 2.040696,
     "end_time": "2025-10-04T00:26:25.192013",
     "exception": false,
     "start_time": "2025-10-04T00:26:23.151317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1876, Test Accuracy: 0.9494\n"
     ]
    }
   ],
   "source": [
    "# Loading best model\n",
    "best_model = ResNet18().to(device)\n",
    "best_model.load_state_dict(logger.best_state)\n",
    "\n",
    "# Testing best model\n",
    "test_loss, test_acc = evaluate(best_model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b20bc186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T00:26:25.217128Z",
     "iopub.status.busy": "2025-10-04T00:26:25.216867Z",
     "iopub.status.idle": "2025-10-04T00:26:25.283109Z",
     "shell.execute_reply": "2025-10-04T00:26:25.282505Z"
    },
    "papermill": {
     "duration": 0.080114,
     "end_time": "2025-10-04T00:26:25.284498",
     "exception": false,
     "start_time": "2025-10-04T00:26:25.204384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.save_all(history_dir=\"history\", models_dir=\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5e029",
   "metadata": {
    "papermill": {
     "duration": 0.011123,
     "end_time": "2025-10-04T00:26:25.307420",
     "exception": false,
     "start_time": "2025-10-04T00:26:25.296297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38053.029971,
   "end_time": "2025-10-04T00:26:27.675839",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-03T13:52:14.645868",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "39d0075219334d19afced2b31b8a169f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_63b689ec102a4a6d873b4975ec1a491b",
       "max": 300,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_957fa996eb884461b737907fcaf0e7bb",
       "tabbable": null,
       "tooltip": null,
       "value": 300
      }
     },
     "42c45caa02534525b65bd291e3514d96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a94faa2abc75419da8e3ae0a3bda8600",
        "IPY_MODEL_39d0075219334d19afced2b31b8a169f",
        "IPY_MODEL_62910abfbfd343068b613e40ea13c799"
       ],
       "layout": "IPY_MODEL_c0e8296fa49543c696621f38aec7b9e5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5454d802960b43c295ae1ef2d77a76f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62910abfbfd343068b613e40ea13c799": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5454d802960b43c295ae1ef2d77a76f5",
       "placeholder": "​",
       "style": "IPY_MODEL_a3a0a13efa6642fc9602197cd82d1bbe",
       "tabbable": null,
       "tooltip": null,
       "value": " 300/300 [2:19:28&lt;00:00, 27.89s/epoch]"
      }
     },
     "63b689ec102a4a6d873b4975ec1a491b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "957fa996eb884461b737907fcaf0e7bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a3a0a13efa6642fc9602197cd82d1bbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a94faa2abc75419da8e3ae0a3bda8600": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d76af3a839814e0bb91a7dd9c04d6398",
       "placeholder": "​",
       "style": "IPY_MODEL_d40d02bd5d1d4b579cd05e30b690795f",
       "tabbable": null,
       "tooltip": null,
       "value": "Epochs: 100%"
      }
     },
     "c0e8296fa49543c696621f38aec7b9e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d40d02bd5d1d4b579cd05e30b690795f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d76af3a839814e0bb91a7dd9c04d6398": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
